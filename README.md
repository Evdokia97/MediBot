# MediBot
This thesis was created in the context of research on the relationship that could be developed between chatbots and biomedical data. More specifically, the history of chatbots has shown us that their evolution is continuous and their potential is endless. However, their potential in biomedical data is still being explored and that is the reason for the existence of this thesis. By choosing to create a qa chatbot and inserting biomedical data - and not - into it, we aim through various tests to evaluate possible performance and to make observations about the reaction of the chatbot in each case.
More specifically, in terms of the data used, we used 1100 abstracts from medical papers of the PubMed library, as well as 250 SQuAD v2.0 data, due to limited computing power. The above samples were divided into sentences, after entering the program, offering 8,737 sentences for comparison. The Bert algorithm was used in the tests in four different models, Roberta, Bert Large, Xlm-r and Biobert. However, we also wanted to observe how the chatbot would react without an algorithm, so we used CountVectorizer, which proved to be the most effective of the five.
In terms of evaluation, 100 experiments were performed in each case, so a total of 500 experimental questions and answers, which were evaluated based on the answers given by each chatbot and the answers that we judged to be correct. The specific answers were compared and evaluated in terms of their similarities, through the metrics f1 score, precision and recall, metrics which were calculated overall and gave comparable results, bringing CounterVectonizer in the first place with Roberta, Bert Large, Xlm-r and Biobert to follow. 



You can run the chatbot easily, by running the Medibot.ipynb.
